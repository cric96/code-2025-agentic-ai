{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a77807f92f26ee",
   "metadata": {},
   "source": [
    "# Agentic AI\n",
    "Questo notebook contiene una serie di semplici esempi per usare le generative AI per fare agentic intelligenti."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a03e5962771a4b3",
   "metadata": {},
   "source": [
    "## LLM Provider\n",
    "Un provider Ã¨ un servizio che fornisce modelli di linguaggio (LLM) per generare testo, rispondere a domande, tradurre lingue, e altro ancora.\n",
    "Noi vedremo sia Ollama (riferimento per caricare *solo* modelli locali) e LM Studio (pensato per la gestione di modelli in locale e remoti e in generale per la prototipazione rapida di agenti AI)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0d2d9f9deba95e",
   "metadata": {},
   "source": [
    "### Ollama\n",
    "Ãˆ un servizio che Ã¨ composto da:\n",
    "- runtime per eseguire modelli di linguaggio in locale\n",
    "- un'interfaccia a linea di comando (CLI) per gestire i modelli e\n",
    "- un'interfaccia web per interagire con i modelli.\n",
    "In automatico, carica e gestisce i modelli open cercando di ottimizzare le risorse del sistema (e.g., GPU, RAM, CPU)."
   ]
  },
  {
   "cell_type": "code",
   "id": "685af62cd555c76b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T14:23:13.046903Z",
     "start_time": "2025-11-10T14:23:12.805833Z"
    }
   },
   "source": [
    "import ollama\n",
    "models = ollama.list().models\n",
    "for model in models:\n",
    "    print(model.model)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qwen3-vl:2b\n",
      "gemma3:270m\n",
      "qwen3:1.7b\n",
      "llama3.2:latest\n",
      "llama3.2:3b\n",
      "qwen2.5:1.5b\n",
      "qwen2.5:3b\n",
      "smollm:latest\n",
      "smollm:360m\n",
      "mxbai-embed-large:latest\n",
      "smollm:135m\n",
      "all-minilm:latest\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "c38b6e7d8b03971d",
   "metadata": {},
   "source": [
    "### Generazione\n",
    "Per generare il testo con un modello, si usa la funzione `ollama.generate`.\n",
    "Accetta come parametri il nome del modello e il prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dfab55160466d5",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "ollama.generate(\"gemma3:270m\", \"Ciao, come stai?\").response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4770951501c6d2b",
   "metadata": {},
   "source": [
    "### OpenAI compatibility\n",
    "Ollama fornisce un'API compatibile con OpenAI, quindi Ã¨ possibile usare librerie che supportano OpenAI per interagire con i modelli Ollama."
   ]
  },
  {
   "cell_type": "code",
   "id": "4177b1087aefe0a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T14:25:16.554434Z",
     "start_time": "2025-11-10T14:25:16.538075Z"
    }
   },
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(\n",
    "    base_url=\"http://localhost:11434/v1\",\n",
    "    api_key=\"none\" # Ollama non richiede API key\n",
    ")\n",
    "client.models.list()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncPage[Model](data=[Model(id='qwen3-vl:2b', created=1762677138, object='model', owned_by='library'), Model(id='gemma3:270m', created=1762623941, object='model', owned_by='library'), Model(id='qwen3:1.7b', created=1762620637, object='model', owned_by='library'), Model(id='llama3.2:latest', created=1762609374, object='model', owned_by='library'), Model(id='llama3.2:3b', created=1762609335, object='model', owned_by='library'), Model(id='qwen2.5:1.5b', created=1741084202, object='model', owned_by='library'), Model(id='qwen2.5:3b', created=1741078970, object='model', owned_by='library'), Model(id='smollm:latest', created=1741069260, object='model', owned_by='library'), Model(id='smollm:360m', created=1740861984, object='model', owned_by='library'), Model(id='mxbai-embed-large:latest', created=1740858009, object='model', owned_by='library'), Model(id='smollm:135m', created=1740855169, object='model', owned_by='library'), Model(id='all-minilm:latest', created=1740855088, object='model', owned_by='library')], object='list')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c84d79ad6f5ab042",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T17:45:45.963643Z",
     "start_time": "2025-11-08T17:45:44.547563Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Ciao! Sto bene, grazie per avermi chiesto un'aiuta. Come stai oggi?\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.completions.create(model=\"gemma3:270m\", prompt=\"Ciao, come stai?\").choices[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b43ba90883a430",
   "metadata": {},
   "source": [
    "## Langchain\n",
    "LangChain Ã¨ una libreria che facilita la costruzione di applicazioni basate su modelli di linguaggio.\n",
    "Abbiamo visto OpenWebUI che ci permette di creare semplici chatbot con modelli locali.\n",
    "Per fare agenti \"custom\" (workflow complessi principalmente) possiamo usare LangChain con modelli locali (tramite Ollama o LM Studio).\n",
    "Langchain principalmente ha bisogno di un modello, noi ci baseremo su ChatOpenAI che supporta modelli di tipo chat."
   ]
  },
  {
   "cell_type": "code",
   "id": "fbc121e30a2defb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T15:19:40.059529Z",
     "start_time": "2025-11-10T15:19:39.228140Z"
    }
   },
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model=\"qwen3:1.7b\",\n",
    "    base_url=\"http://localhost:11434/v1\",\n",
    "    # model=\"qwen/qwen3-vl-4b\",\n",
    "    # base_url=\"http://127.0.0.1:1234/v1\",\n",
    "    api_key=\"none\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "b540198951e764be",
   "metadata": {},
   "source": [
    "`invoke` permette di invocare il modello con un singolo messaggio."
   ]
  },
  {
   "cell_type": "code",
   "id": "99825574e79800e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T15:34:11.933521Z",
     "start_time": "2025-11-10T15:33:57.993136Z"
    }
   },
   "source": "model.invoke(\"Che ore sono?\").content",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ciao! Sto cercando di capire che ora Ã¨, ma non ho accesso a dati real-time. Posso chiederti dove ti trovi? CosÃ¬ potrÃ² darti la corretta ora locale. ðŸ˜Š'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "71ef3474d30cfd98",
   "metadata": {},
   "source": [
    "### Langchain agents\n",
    "Langhchain, sopra questi modelli, permette di creare agenti AI che possono eseguire compiti piÃ¹ complessi.\n",
    "Possono fare ragionamenti, prendere decisioni, e interagire con strumenti esterni (tools).\n",
    "Per creare un agente semplice, si usa `create_agent`."
   ]
  },
  {
   "cell_type": "code",
   "id": "ed3a6b76bbfcf17b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T15:20:12.638748Z",
     "start_time": "2025-11-10T15:20:12.366759Z"
    }
   },
   "source": [
    "from langchain.agents import create_agent\n",
    "agent = create_agent(\n",
    "    model=model\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "51f452655f4a5228",
   "metadata": {},
   "source": [
    "Anche qui, si deve utilizzare `invoke` per interagire con l'agente.\n",
    "La differenza Ã¨ che l'agente acceta una lista di messaggi (come nei modelli chat).\n",
    "I messaggi hanno anche un ruolo (user, assistant, system)."
   ]
  },
  {
   "cell_type": "code",
   "id": "31b5e0c5c7b7b0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T15:20:37.633181Z",
     "start_time": "2025-11-10T15:20:16.513434Z"
    }
   },
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "agent.invoke({\n",
    "    \"messages\": [HumanMessage(\"Che ore sone?\")]\n",
    "})"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Che ore sone?', additional_kwargs={}, response_metadata={}, id='93b342b6-05ea-4b09-950e-60137738e077'),\n",
       "  AIMessage(content='La domanda \"Che ore sone?\" (che ore Ã¨ ora?) non ha un risposta unica senza sapere la tua zona oraria. Il tempo varia in base alla tua ubicazione geografica. \\n\\nSe vuoi, puoi dirmi il tuo luogo o la tua zona oraria (es. Italia, Stati Uniti, Brasile, etc.), e ti aiuto ad indicare l\\'ora corretta! ðŸ˜Š\\n\\n**Come verificare l\\'ora corrente:**  \\n- Usa un cronometro online (es. [TimeAndDate](https://www.timeanddate.com/))  \\n- Controlla un\\'app di navigazione o un dispositivo mobile  \\n- Verifica il tuo orologio o un calendario  \\n\\nSe hai un\\'informazione su di tua, fammi sapere! ðŸŒ', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 361, 'prompt_tokens': 15, 'total_tokens': 376, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'qwen3:1.7b', 'system_fingerprint': 'fp_ollama', 'id': 'chatcmpl-490', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--1e3bd851-71c1-4e4b-b72d-5aadd1c04d97-0', usage_metadata={'input_tokens': 15, 'output_tokens': 361, 'total_tokens': 376, 'input_token_details': {}, 'output_token_details': {}})]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "ccd2288835ca0960",
   "metadata": {},
   "source": [
    "Per la conversazione, si puÃ² simulare una chat mantenendo lo stato della conversazione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8620b6bf02b38b0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T17:56:27.890929Z",
     "start_time": "2025-11-08T17:54:57.280696Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent: Sono bene, ma posso aiutarti con qualcosa?\n",
      "Agent: 3 + 2 = 5. Il risultato Ã¨ 5.\n",
      "Agent: La data Ã¨ il 11 aprile 2023, e le ore sono 14:30. C'Ã¨ qualcosa che posso aiutarti oggi?\n"
     ]
    }
   ],
   "source": [
    "steps = 3\n",
    "messages = []\n",
    "for i in range(steps):\n",
    "    user_input = input(\"User: \")\n",
    "    messages.append(HumanMessage(content=user_input))\n",
    "    response = agent.invoke({\"messages\": messages})\n",
    "    print(f\"Agent: {response['messages'][-1].content}\")\n",
    "    messages.append(response['messages'][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c506c0541b87cb",
   "metadata": {},
   "source": [
    "## Strumenti\n",
    "Un LLM non puÃ² fare tutto da solo. Spesso ha bisogno di strumenti esterni per ottenere informazioni aggiornate o eseguire calcoli.\n",
    "Questo si basa principalmente sull'idea di \"tool use\", dove l'agente decide quando e come usare uno strumento.\n",
    "Questa cosa, puÃ² essere fatta via prompt engineering.\n",
    "Si deve:\n",
    "- Definire gli strumenti disponibili\n",
    "- Fornire un prompt che spiega come usare gli strumenti\n",
    "- Analizzare la risposta del modello per vedere se vuole usare uno strumento\n",
    "- Eseguire lo strumento se necessario e fornire il risultato al modello per una risposta"
   ]
  },
  {
   "cell_type": "code",
   "id": "c6c67d574e59108d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T15:36:03.738458Z",
     "start_time": "2025-11-10T15:36:03.735353Z"
    }
   },
   "source": [
    "# Tool definitions\n",
    "from datetime import datetime\n",
    "TOOLS = {\n",
    "    \"get_current_time\": lambda: datetime.now().strftime(\"%H:%M:%S\"),\n",
    "    \"get_current_date\": lambda: datetime.now().strftime(\"%Y-%m-%d\")\n",
    "}\n"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "650e879da692e504",
   "metadata": {},
   "source": [
    "Dati questi tools, possiamo creare un prompt che spiega come usarli."
   ]
  },
  {
   "cell_type": "code",
   "id": "2cf3158046c20905",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T15:36:04.772076Z",
     "start_time": "2025-11-10T15:36:04.769328Z"
    }
   },
   "source": [
    "TOOL_PROMPT = \"\"\"\n",
    "System Prompt:\n",
    "You are an AI agent that can use the following tools to assist users:\n",
    "Tools:\n",
    "1. Get Current Time\n",
    "   - Description: Returns the current time in HH:MM:SS format.\n",
    "   - Interface: get_current_time() -> str\n",
    "2. Get Current Date\n",
    "   - Description: Returns the current date in YYYY-MM-DD format.\n",
    "   - Interface: get_current_date() -> str\n",
    "\n",
    "When given a user request, decide if you need to use a tool. If so, generate a command in the format:\n",
    "<tool_name>()\n",
    "following the tool's Interface (e.g., get_current_time(), or get_current_date()).\n",
    "\n",
    "If you use a tool, respond with ONLY the tool call in the exact format specified.\n",
    "If you don't need a tool, respond normally to the user.\n",
    "\"\"\"\n"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "b9661f9df382cf97",
   "metadata": {},
   "source": [
    "Devo poi fare in modo che l'agente sia in grado di interpretare il prompt e chiamare i tools.\n",
    "Per questo, si potrebbero usare espressioni regolari per estrarre il nome dello strumento dalla risposta del modello."
   ]
  },
  {
   "cell_type": "code",
   "id": "4713662481e6d90b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T15:36:07.949309Z",
     "start_time": "2025-11-10T15:36:07.945740Z"
    }
   },
   "source": [
    "import re\n",
    "def parse_tool_call(response: str):\n",
    "    \"\"\"Parse tool_name() from response\"\"\"\n",
    "    if match := re.search(r'(\\w+)\\(\\)', response):\n",
    "        tool_name = match.group(1)\n",
    "        return tool_name, {}\n",
    "    return None\n"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "80b6ffa295acc7b6",
   "metadata": {},
   "source": [
    "Infine, scrivo l'agente \"vero e proprio\" che usa i tools via prompt engineering."
   ]
  },
  {
   "cell_type": "code",
   "id": "b6214a70747a5ac6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T15:36:49.257715Z",
     "start_time": "2025-11-10T15:36:49.253941Z"
    }
   },
   "source": [
    "def agent_with_tools_prompt(user_input: str) -> str:\n",
    "    \"\"\"Agent that uses tools via prompt engineering\"\"\"\n",
    "    response = model.invoke(f\"{TOOL_PROMPT}\\n\\nUser: {user_input}\\nAssistant:\").content\n",
    "    print(f\"LLM Response: {response}\")\n",
    "\n",
    "    if tool_call := parse_tool_call(response):\n",
    "        tool_name, params = tool_call\n",
    "        print(f\"Tool call: {tool_name}()\")\n",
    "\n",
    "        if tool_name in TOOLS:\n",
    "            result = TOOLS[tool_name]()\n",
    "            print(f\"Result: {result}\")\n",
    "            return model.invoke(\n",
    "                f\"{TOOL_PROMPT}\\n\\nUser: {user_input}\\n\"\n",
    "                f\"Tool {tool_name} returned: {result}\\nProvide final answer:\"\n",
    "            ).content\n",
    "        return f\"Error: Tool '{tool_name}' not found.\"\n",
    "\n",
    "    return response\n"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "c47d9f26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T15:37:57.957294Z",
     "start_time": "2025-11-10T15:37:02.118637Z"
    }
   },
   "source": [
    "# Esempi d'uso\n",
    "\n",
    "print(\"Risultato: \" + agent_with_tools_prompt(\"Che ore sono adesso?\"))\n",
    "\n",
    "print(\"Risultato: \" + agent_with_tools_prompt(\"Qual Ã¨ la data di oggi?\"))\n",
    "\n",
    "print(\"Risultato: \" + agent_with_tools_prompt(\"In che mese siamo?\"))\n",
    "\n",
    "print(\"Risultato: \" + agent_with_tools_prompt(\"Ciao, come stai?\"))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response: <get_current_time()>\n",
      "Tool call: get_current_time()\n",
      "Result: 16:37:09\n",
      "Risultato: 16:37:09\n",
      "LLM Response: <get_current_date()>\n",
      "Tool call: get_current_date()\n",
      "Result: 2025-11-10\n",
      "Risultato: La data di oggi Ã¨ 2025-11-10.\n",
      "LLM Response: <get_current_date()>\n",
      "Tool call: get_current_date()\n",
      "Result: 2025-11-10\n",
      "Risultato: The current month is November.\n",
      "LLM Response: Ciao! Sono un AI e non ho un corpo, perÃ² posso aiutarti con qualsiasi cosa necessiti. Come posso aiutarti oggi?\n",
      "Risultato: Ciao! Sono un AI e non ho un corpo, perÃ² posso aiutarti con qualsiasi cosa necessiti. Come posso aiutarti oggi?\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "b1054e20",
   "metadata": {},
   "source": [
    "## LangChain tools\n",
    "LangChain predispone nella modalitÃ  \"Agent\" di utilizzare direttamente i tools.\n",
    "Ãˆ possibile farlo sia con MCP che con funzioni python pure (via @tool)."
   ]
  },
  {
   "cell_type": "code",
   "id": "fd9091d045d8ef43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T15:39:21.537273Z",
     "start_time": "2025-11-10T15:39:21.526713Z"
    }
   },
   "source": [
    "from langchain.tools import tool\n",
    "from datetime import datetime\n",
    "\n",
    "@tool\n",
    "def get_current_time() -> str:\n",
    "    \"\"\"\n",
    "    Ritorna l'ora corrente nel formato HH:MM:SS\n",
    "    \"\"\"\n",
    "    return datetime.now().strftime(\"%H:%M:%S\")\n",
    "\n",
    "agent_with_time = create_agent(\n",
    "    model=model,\n",
    "    tools=[get_current_time]\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "id": "bdc36394ba563c07",
   "metadata": {},
   "source": [
    "Una funzione annotata in questo modo, viene automaticamente convertita in uno strumento che l'agente puÃ² usare."
   ]
  },
  {
   "cell_type": "code",
   "id": "8f987fdec3ee458b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T15:39:24.326215Z",
     "start_time": "2025-11-10T15:39:24.322434Z"
    }
   },
   "source": [
    "get_current_time"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredTool(name='get_current_time', description=\"Ritorna l'ora corrente nel formato HH:MM:SS\", args_schema=<class 'langchain_core.utils.pydantic.get_current_time'>, func=<function get_current_time at 0x7fbef465cc20>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "id": "3a575081a438aed1",
   "metadata": {},
   "source": [
    "Ora l'agente *puÃ²* usare il tool in modo autonomo quando ne ha bisogno"
   ]
  },
  {
   "cell_type": "code",
   "id": "161ca16b10e65ae3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T15:40:15.635118Z",
     "start_time": "2025-11-10T15:39:59.558953Z"
    }
   },
   "source": [
    "result = agent_with_time.invoke({\n",
    "    \"messages\": [HumanMessage(\"Che ore sono?\")]\n",
    "})\n",
    "\n",
    "result['messages'][2]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToolMessage(content='16:40:07', name='get_current_time', id='b0b02330-0d3d-41c1-878f-eee79c87e4ff', tool_call_id='call_5f04lorh')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "505907e7fa6bd142",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T15:41:56.734911Z",
     "start_time": "2025-11-10T15:41:56.731577Z"
    }
   },
   "source": "result['messages'][3]",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"L'ora corrente Ã¨ 16:40:07.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 147, 'prompt_tokens': 183, 'total_tokens': 330, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'qwen3:1.7b', 'system_fingerprint': 'fp_ollama', 'id': 'chatcmpl-669', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--2d8b93bc-c2d9-4910-bcd2-ca9ec3d743cf-0', usage_metadata={'input_tokens': 183, 'output_tokens': 147, 'total_tokens': 330, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "id": "a6db16cfbe19b275",
   "metadata": {},
   "source": [
    "Ãˆ possibile, infine, basarsi su MCP per caricare tools da server remoti.\n",
    "Eseguendo lo script `time-mcp.py` si avvia un server MCP che espone un tool per ottenere l'ora corrente."
   ]
  },
  {
   "cell_type": "code",
   "id": "d14d414502aefc9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T18:41:34.446727Z",
     "start_time": "2025-11-08T18:41:15.524441Z"
    }
   },
   "source": [
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "client = MultiServerMCPClient(\n",
    "    {\n",
    "        \"time\": {\n",
    "            \"transport\": \"streamable_http\",\n",
    "            \"url\": \"http://localhost:8000/mcp\",\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "tools = await client.get_tools() # prendo i tools dal server MCP\n",
    "agent = create_agent(model=model, tools=tools)\n",
    "time_response = await agent.ainvoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"che ore sono??\"}]}\n",
    ")\n",
    "# Mostra la risposta finale dell'agente in modo piÃ¹ leggibile\n",
    "print(\"Risposta dell'agente:\")\n",
    "print(time_response['messages'][-1].content)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Risposta dell'agente:\n",
      "Ist tempo corrente Ã¨ **28 settembre 2025 alle 19:41** (orario locale). Se necessiti di informazioni aggiornate, puoi ripetere la domanda! ðŸŒž\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Ãˆ possibile anche sfruttare MCP in locale usando Docker.\n",
    "In questo esempio, usiamo `docker mcp gateway run --servers=time` per avviare un server MCP locale che espone il tool per ottenere l'ora corrente."
   ],
   "id": "6a45824a24a52e70"
  },
  {
   "cell_type": "code",
   "id": "baae6993f6d2516b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T18:44:13.215601Z",
     "start_time": "2025-11-08T18:43:49.753964Z"
    }
   },
   "source": [
    "from mcp import ClientSession\n",
    "from langchain_mcp_adapters.tools import load_mcp_tools\n",
    "from mcp.client.stdio import stdio_client, StdioServerParameters\n",
    "\n",
    "server_params = StdioServerParameters(\n",
    "    command=\"docker\",\n",
    "    args=[\"mcp\", \"gateway\", \"run\", \"--servers=time\"]\n",
    ")\n",
    "\n",
    "async with stdio_client(server_params) as (read, write):\n",
    "    async with ClientSession(read, write) as session:\n",
    "        await session.initialize()\n",
    "        tools = await load_mcp_tools(session)\n",
    "        agent_with_mcp = create_agent(\n",
    "            model=model,\n",
    "            tools=tools\n",
    "        )\n",
    "        result = await agent_with_mcp.ainvoke({  # Add await here\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": \"Che ore sono? (in UTC)\"}]\n",
    "        })\n",
    "        print(result['messages'][-1].content)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In UTC time, it's currently **October 8, 2025 at 18:44**. The time zone is set to UTC, and no daylight saving adjustments are currently in effect. Let me know if you need the time in a different timezone!\n"
     ]
    }
   ],
   "execution_count": 47
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
